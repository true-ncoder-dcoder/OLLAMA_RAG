{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d39e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.1.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx<0.26.0,>=0.25.2 (from ollama)\n",
      "  Using cached httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting anyio (from httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Using cached ollama-0.1.7-py3-none-any.whl (9.4 kB)\n",
      "Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, idna, h11, certifi, httpcore, anyio, httpx, ollama\n",
      "Successfully installed anyio-4.3.0 certifi-2024.2.2 h11-0.14.0 httpcore-1.0.4 httpx-0.25.2 idna-3.6 ollama-0.1.7 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c7abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The color of the sky appears blue due to a process called scattering. When the sun's rays enter Earth's atmosphere, they collide with molecules and particles in the air, such as nitrogen and oxygen. These collisions cause the light to scatter in all directions. Blue light has shorter wavelengths and gets scattered more easily than other colors, so it gets dispersed throughout the sky, making it appear blue during a clear day. This is known as Rayleigh scattering. At sunrise or sunset, when the sun's rays have to pass through more of the atmosphere, the sky can take on other hues, such as red, orange, and pink.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model='mistral', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412b831b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'mistral:latest',\n",
       "   'model': 'mistral:latest',\n",
       "   'modified_at': '2024-03-11T15:47:42.226703063+05:30',\n",
       "   'size': 4109865159,\n",
       "   'digest': '61e88e884507ba5e06c49b40e6226884b2a16e872382c2b44a42f2d119d804a5',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '7B',\n",
       "    'quantization_level': 'Q4_0'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ff9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
      "  Using cached langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
      "  Using cached langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.23-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/114.8 kB\u001b[0m \u001b[31m284.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in ./ollama_venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.29->langchain) (4.3.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.29->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.9.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.16.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ollama_venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ollama_venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ollama_venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.1.11-py3-none-any.whl (807 kB)\n",
      "Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (387 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
      "Using cached langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "Using cached pydantic_core-2.16.3-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached orjson-3.9.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, PyYAML, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, frozenlist, charset-normalizer, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 attrs-23.2.0 charset-normalizer-3.3.2 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.9.15 packaging-23.2 pydantic-2.6.3 pydantic-core-2.16.3 requests-2.31.0 tenacity-8.2.3 typing-extensions-4.10.0 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae763f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38747ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m400.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0804c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests>=2.28 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (2.6.3)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.28.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (4.10.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Using cached pulsar_client-3.4.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.2 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting tqdm>=4.65.0 (from chromadb)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.1.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./ollama_venv/lib/python3.11/site-packages (from chromadb) (3.9.15)\n",
      "Requirement already satisfied: packaging>=19.0 in ./ollama_venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in ./ollama_venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ollama_venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ollama_venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.28.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-1.4.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./ollama_venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./ollama_venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./ollama_venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./ollama_venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./ollama_venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ollama_venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: h11>=0.8 in ./ollama_venv/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in ./ollama_venv/lib/python3.11/site-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (4.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ollama_venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl (198 kB)\n",
      "Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "Using cached build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "Using cached opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Using cached opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached pulsar_client-3.4.0-cp311-cp311-macosx_10_15_universal2.whl (10.9 MB)\n",
      "Using cached tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Using cached uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
      "Using cached importlib_resources-6.1.3-py3-none-any.whl (34 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
      "Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
      "Using cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Using cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "Using cached uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "Using cached watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached requests_oauthlib-1.4.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Installing collected packages: pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, websocket-client, uvloop, tqdm, sympy, python-dotenv, pyproject_hooks, pyasn1, pulsar-client, protobuf, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, importlib-resources, humanfriendly, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, typer, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, importlib-metadata, huggingface_hub, googleapis-common-protos, deprecated, coloredlogs, build, tokenizers, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 build-1.1.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 filelock-3.13.1 flatbuffers-24.3.7 fsspec-2024.2.0 google-auth-2.28.2 googleapis-common-protos-1.62.0 grpcio-1.62.1 httptools-0.6.1 huggingface_hub-0.21.4 humanfriendly-10.0 importlib-metadata-6.11.0 importlib-resources-6.1.3 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.4.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 requests-oauthlib-1.4.0 rsa-4.9 starlette-0.36.3 sympy-1.12 tokenizers-0.15.2 tqdm-4.66.2 typer-0.9.0 uvicorn-0.28.0 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 wrapt-1.16.0 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af45f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:  I apologize for any confusion, but there is no creator explicitly mentioned in the context provided regarding the \"ChatGPT Power Course.\" The context only discusses how ChatGPT can produce high-quality content quickly and provides examples of business models using it for copywriting. If you have more specific information about who created this course, please let me know and I will be happy to help.\n",
      "Result 2:  1. AI Content Generation and Editing Service: Create a business offering high-quality, AI-generated content for various industries such as marketing, education, or entertainment. Utilize AI tools like ChatGPT to produce engaging scripts, blog articles, or social media posts copies. Provide editing services to ensure the final output meets clients' expectations.\n",
      "\n",
      "2. AI Keyword Research and Content Optimization: Specialize in using AI, such as ChatGPT, for conducting thorough keyword research and optimizing content to rank higher on search engines like Google. Offer this service to businesses looking to increase their online presence and organic traffic.\n",
      "\n",
      "3. AI-assisted Transcription and Voiceover Services: Start a business focusing on transcribing audio or video files using advanced AI models like ChatGPT for accurate and quick results. Also, offer voiceover services by generating high-quality scripts utilizing the same AI technology to create professional-sounding recordings.\n",
      "\n",
      "4. AI Tutoring and Coaching: Develop an educational platform using AI tools like ChatGPT to provide personalized tutoring or coaching sessions in various subjects. Create customized lesson plans based on individual students' needs and progress, making learning more effective and engaging.\n",
      "\n",
      "5. AI-driven Customer Support and Live Chat: Use AI technology like ChatGPT to create a 24/7 customer support system for businesses, offering quick solutions to common queries through an intuitive chat interface. Implement sentiment analysis and personalized responses for a better user experience.\n",
      "\n",
      "6. AI Social Media Management and Content Creation: Create a social media management agency focusing on utilizing AI tools like ChatGPT to generate unique, engaging, and optimized content for various clients' social media channels. Offer content creation, scheduling, and analytics services to increase brand awareness and engagement.\n",
      "\n",
      "7. AI-powered Personalized Marketing Campaigns: Develop targeted marketing campaigns using AI-generated content from tools like ChatGPT to create personalized email or ad copy based on individual users' preferences and browsing history. Use predictive analysis to optimize campaign performance.\n",
      "\n",
      "8. AI Virtual Assistant Services: Provide virtual assistant services utilizing advanced AI models like ChatGPT to handle various tasks such as scheduling appointments, managing emails, making reservations, and providing quick answers to common queries. Offer customization options for a more personalized experience.\n",
      "\n",
      "9. AI-generated Music Composition and Production: Create unique music compositions using AI tools like ChatGPT to generate melodies, chord progressions, and even lyrics based on input from artists or bands. Provide production services to help bring these creations to life.\n",
      "\n",
      "10. AI-based Recipe Creation and Meal Planning: Use AI technology to develop a recipe generation and meal planning platform for individuals with dietary restrictions or those looking to expand their culinary skills. Offer personalized meal plans based on nutritional information and preferences.\n",
      "\n",
      "11. AI-driven News and Current Events Aggregation: Create an AI-powered news aggregator that utilizes advanced language models like ChatGPT to provide users with a customized newsfeed based on their interests and preferences. Offer summarization services for long articles, making it easier to consume content quickly.\n",
      "\n",
      "12. AI-based Travel Planning and Recommendations: Develop an AI-powered travel planning platform that offers personalized recommendations based on user preferences and real-time data from various sources. Utilize advanced language models like ChatGPT to generate customized itineraries, provide translations for foreign languages, and answer frequently asked travel questions.\n"
     ]
    }
   ],
   "source": [
    "PDF_FILE_PATH = 'ChatGPT Power Course.pdf'  # Update with your file path\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "OLLAMA_MODEL_NAME = 'mistral'\n",
    "\n",
    "# Function to load and split the PDF document\n",
    "def load_and_split_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Loads a PDF document and splits it into pages.\n",
    "    Args:\n",
    "    file_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "    list: List of pages from the PDF document.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load_and_split()\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text(pages, chunk_size, chunk_overlap):\n",
    "    \"\"\"\n",
    "    Splits text from pages into smaller chunks.\n",
    "    Args:\n",
    "    pages (list): List of pages from the document.\n",
    "    chunk_size (int): Size of each text chunk.\n",
    "    chunk_overlap (int): Overlap between consecutive chunks.\n",
    "    Returns:\n",
    "    list: List of text chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(pages)\n",
    "\n",
    "# Function to create embeddings and vector store\n",
    "def create_embeddings_and_vectorstore(splits, model_name):\n",
    "    \"\"\"\n",
    "    Creates embeddings and a vector store from document splits.\n",
    "    Args:\n",
    "    splits (list): List of document splits.\n",
    "    model_name (str): Name of the Ollama model to use.\n",
    "    Returns:\n",
    "    Chroma: Vector store object.\n",
    "    \"\"\"\n",
    "    embeddings = OllamaEmbeddings(model=model_name)\n",
    "    return Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "# Function to format documents for context\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    Formats a list of documents into a single string.\n",
    "    Args:\n",
    "    docs (list): List of documents.\n",
    "    Returns:\n",
    "    str: Formatted string of document contents.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Function to query Ollama LLM with context\n",
    "def ollama_llm(question, context):\n",
    "    \"\"\"\n",
    "    Queries the Ollama LLM with a question and context.\n",
    "    Args:\n",
    "    question (str): The question to ask.\n",
    "    context (str): The context for the question.\n",
    "    Returns:\n",
    "    str: The response from the LLM.\n",
    "    \"\"\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model=OLLAMA_MODEL_NAME, messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Function to execute the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    \"\"\"\n",
    "    Executes the RAG chain to get an answer to a question.\n",
    "    Args:\n",
    "    question (str): The question to ask.\n",
    "    retriever: The retriever object for document retrieval.\n",
    "    Returns:\n",
    "    str: The answer to the question.\n",
    "    \"\"\"\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# Main Execution Flow\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the RAG workflow.\n",
    "    \"\"\"\n",
    "    pages = load_and_split_pdf(PDF_FILE_PATH)\n",
    "    splits = split_text(pages, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "    vectorstore = create_embeddings_and_vectorstore(splits, OLLAMA_MODEL_NAME)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Example Queries\n",
    "    query1 = \"Who is the creator of ChatGPT Power Course?\"\n",
    "    result1 = rag_chain(query1, retriever)\n",
    "    print(\"Result 1:\", result1)\n",
    "\n",
    "    query2 = \"Give me 12 unique prompts to help you 10X your productivity with AI and become an expert.\"\n",
    "    result2 = rag_chain(query2, retriever)\n",
    "    print(\"Result 2:\", result2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f140716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_venv",
   "language": "python",
   "name": "ollama_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
